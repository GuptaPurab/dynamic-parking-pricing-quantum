{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧪 Week 1 Experiments: Dynamic Parking with Your Data\n",
    "\n",
    "This notebook analyzes your actual parking dataset (`dataset.csv`) to build foundational understanding for our quantum ML project.\n",
    "\n",
    "## 🎯 Your Dataset Overview\n",
    "- **18,369 records** from parking system `BHMBCCMKT01`\n",
    "- **Location**: Guwahati, India (26.14°N, 91.73°E)\n",
    "- **Capacity**: 577 parking spaces\n",
    "- **Features**: Occupancy, VehicleType, TrafficCondition, QueueLength, SpecialDays\n",
    "- **Time Range**: October 2016 with hourly updates\n",
    "\n",
    "## 🧠 Learning Objectives\n",
    "1. **Analyze** your real parking data patterns\n",
    "2. **Engineer** features for time series prediction\n",
    "3. **Build** a classical ML baseline for price prediction\n",
    "4. **Explore** quantum computing fundamentals\n",
    "5. **Design** quantum feature encoding for your parking data\n",
    "\n",
    "## ⚙️ Setup & Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Quantum Computing\n",
    "from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister\n",
    "from qiskit import execute, Aer\n",
    "from qiskit.visualization import plot_histogram, plot_circuit_layout\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display settings\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✅ All imports successful!\")\n",
    "print(f\"📊 NumPy: {np.__version__}\")\n",
    "print(f\"🐼 Pandas: {pd.__version__}\")\n",
    "print(f\"🚀 Ready to explore!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 🔍 Experiment 1: Your Real Data Analysis (45 minutes)\n",
    "\n",
    "**Goal**: Analyze your actual parking dataset and understand patterns for quantum ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load Your Actual Parking Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your actual parking dataset\n",
    "print(\"📂 Loading your parking dataset...\")\n",
    "parking_raw = pd.read_csv('../dataset.csv')\n",
    "\n",
    "print(f\"✅ Loaded {len(parking_raw):,} records from BHMBCCMKT01 parking system\")\n",
    "print(f\"📊 Raw data shape: {parking_raw.shape}\")\n",
    "print(f\"🗓️ Date range: {parking_raw['LastUpdatedDate'].min()} to {parking_raw['LastUpdatedDate'].max()}\")\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"\\n🔍 First 5 rows of your data:\")\n",
    "parking_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_parking_data(df):\n",
    "    \"\"\"\n",
    "    Process raw parking data into features suitable for ML\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a copy\n",
    "    data = df.copy()\n",
    "    \n",
    "    # Parse datetime information\n",
    "    data['datetime'] = pd.to_datetime(data['LastUpdatedDate'] + ' ' + data['LastUpdatedTime'])\n",
    "    data['hour'] = data['datetime'].dt.hour\n",
    "    data['day_of_week'] = data['datetime'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "    data['is_weekend'] = (data['day_of_week'] >= 5).astype(int)\n",
    "    \n",
    "    # Calculate occupancy rate (current occupancy / total capacity)\n",
    "    data['occupancy_rate'] = data['Occupancy'] / data['Capacity']\n",
    "    \n",
    "    # Map categorical features to numeric\n",
    "    traffic_map = {'low': 1, 'average': 2, 'high': 3}\n",
    "    vehicle_map = {'cycle': 1, 'bike': 2, 'car': 3, 'truck': 4}\n",
    "    \n",
    "    data['traffic_numeric'] = data['TrafficConditionNearby'].map(traffic_map)\n",
    "    data['vehicle_numeric'] = data['VehicleType'].map(vehicle_map)\n",
    "    \n",
    "    # Use queue length and special day flag as-is\n",
    "    data['queue_length'] = data['QueueLength']\n",
    "    data['is_special_day'] = data['IsSpecialDay']\n",
    "    \n",
    "    # Create price target based on occupancy and demand factors\n",
    "    # This is a business rule we'll use as our target for ML\n",
    "    base_price = 10.0  # Base price in currency units\n",
    "    \n",
    "    # Dynamic pricing formula based on parking demand theory\n",
    "    data['target_price'] = base_price * (\n",
    "        1.0 +                                      # Base multiplier\n",
    "        1.5 * data['occupancy_rate'] +             # Occupancy effect (150% max)\n",
    "        0.3 * (data['traffic_numeric'] - 1) / 2 +  # Traffic effect (30% max)\n",
    "        0.2 * data['queue_length'] / 10 +          # Queue effect (20% for queue=10)\n",
    "        0.4 * data['is_special_day'] +             # Special day premium\n",
    "        0.1 * (data['vehicle_numeric'] - 1) / 3    # Vehicle type effect\n",
    "    )\n",
    "    \n",
    "    # Rush hour effects (morning: 7-9, evening: 17-19)\n",
    "    rush_hour_morning = ((data['hour'] >= 7) & (data['hour'] <= 9)).astype(int)\n",
    "    rush_hour_evening = ((data['hour'] >= 17) & (data['hour'] <= 19)).astype(int)\n",
    "    data['is_rush_hour'] = (rush_hour_morning | rush_hour_evening).astype(int)\n",
    "    \n",
    "    # Add rush hour premium\n",
    "    data['target_price'] *= (1 + 0.2 * data['is_rush_hour'])\n",
    "    \n",
    "    # Round price to 2 decimal places\n",
    "    data['target_price'] = np.round(data['target_price'], 2)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Process the data\n",
    "print(\"⚙️ Processing and engineering features...\")\n",
    "parking_data = preprocess_parking_data(parking_raw)\n",
    "\n",
    "# Select relevant columns for analysis\n",
    "analysis_columns = [\n",
    "    'datetime', 'hour', 'day_of_week', 'is_weekend', 'is_rush_hour',\n",
    "    'occupancy_rate', 'queue_length', 'traffic_numeric', 'vehicle_numeric',\n",
    "    'is_special_day', 'target_price'\n",
    "]\n",
    "\n",
    "parking_data = parking_data[analysis_columns].copy()\n",
    "\n",
    "print(f\"✅ Processed data shape: {parking_data.shape}\")\n",
    "print(f\"📊 Generated target prices ranging from ${parking_data['target_price'].min():.2f} to ${parking_data['target_price'].max():.2f}\")\n",
    "\n",
    "# Check for any missing values\n",
    "missing_values = parking_data.isnull().sum()\n",
    "if missing_values.sum() > 0:\n",
    "    print(f\"\\n⚠️ Missing values detected:\")\n",
    "    print(missing_values[missing_values > 0])\n",
    "    # Drop rows with missing values for this analysis\n",
    "    parking_data = parking_data.dropna()\n",
    "    print(f\"📊 After removing missing values: {parking_data.shape}\")\n",
    "else:\n",
    "    print(\"✅ No missing values found!\")\n",
    "\n",
    "# Display processed data\n",
    "print(\"\\n🔍 Processed data sample:\")\n",
    "parking_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"📈 Your Dataset Analysis:\")\n",
    "print(f\"Total samples: {len(parking_data):,}\")\n",
    "print(f\"Features: {len(parking_data.columns)}\")\n",
    "print(f\"Time span: {parking_data['datetime'].min()} to {parking_data['datetime'].max()}\")\n",
    "print(f\"Price range: ${parking_data['target_price'].min():.2f} - ${parking_data['target_price'].max():.2f}\")\n",
    "print(f\"Avg occupancy rate: {parking_data['occupancy_rate'].mean():.1%}\")\n",
    "print(f\"Peak occupancy: {parking_data['occupancy_rate'].max():.1%}\")\n",
    "\n",
    "# Check data distribution\n",
    "print(\"\\n🔍 Data Characteristics:\")\n",
    "print(f\"• Vehicle types: {len(parking_raw['VehicleType'].unique())} types - {list(parking_raw['VehicleType'].unique())}\")\n",
    "print(f\"• Traffic conditions: {len(parking_raw['TrafficConditionNearby'].unique())} levels - {list(parking_raw['TrafficConditionNearby'].unique())}\")\n",
    "print(f\"• Special days: {parking_data['is_special_day'].sum()} out of {len(parking_data)} records ({parking_data['is_special_day'].mean():.1%})\")\n",
    "print(f\"• Rush hour records: {parking_data['is_rush_hour'].sum():,} ({parking_data['is_rush_hour'].mean():.1%})\")\n",
    "\n",
    "# Missing values check\n",
    "missing_count = parking_data.isnull().sum().sum()\n",
    "if missing_count > 0:\n",
    "    print(f\"⚠️ Missing values: {missing_count}\")\n",
    "else:\n",
    "    print(\"✅ No missing values in processed data!\")\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\n📊 Statistical Summary:\")\n",
    "parking_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('🔍 Parking Data Exploration', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Price distribution\n",
    "axes[0,0].hist(parking_data['target_price'], bins=30, alpha=0.7, color='skyblue')\n",
    "axes[0,0].set_title('Generated Price Distribution')\n",
    "axes[0,0].set_xlabel('Price ($)')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "\n",
    "# 2. Occupancy vs Price\n",
    "axes[0,1].scatter(parking_data['occupancy_rate'], parking_data['target_price'], \n",
    "                  alpha=0.6, color='coral')\n",
    "axes[0,1].set_title('Occupancy vs Target Price')\n",
    "axes[0,1].set_xlabel('Occupancy Rate')\n",
    "axes[0,1].set_ylabel('Price ($)')\n",
    "\n",
    "# 3. Hourly demand patterns\n",
    "hourly_avg = parking_data.groupby('hour')['occupancy_rate'].mean()\n",
    "axes[0,2].plot(hourly_avg.index, hourly_avg.values, marker='o', color='green')\n",
    "axes[0,2].set_title('Average Occupancy by Hour')\n",
    "axes[0,2].set_xlabel('Hour of Day')\n",
    "axes[0,2].set_ylabel('Avg Occupancy Rate')\n",
    "axes[0,2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Traffic vs Price\n",
    "traffic_prices = parking_data.groupby('traffic_numeric')['target_price'].mean()\n",
    "traffic_labels = ['Low', 'Average', 'High']\n",
    "axes[1,0].bar(range(len(traffic_prices)), traffic_prices.values, color='purple', alpha=0.7)\n",
    "axes[1,0].set_title('Average Price by Traffic Condition')\n",
    "axes[1,0].set_xlabel('Traffic Level')\n",
    "axes[1,0].set_ylabel('Avg Price ($)')\n",
    "axes[1,0].set_xticks(range(len(traffic_prices)))\n",
    "axes[1,0].set_xticklabels(traffic_labels)\n",
    "\n",
    "# 5. Weekend vs Weekday\n",
    "weekend_comparison = parking_data.groupby('is_weekend')[['occupancy_rate', 'target_price']].mean()\n",
    "x = np.arange(2)\n",
    "width = 0.35\n",
    "axes[1,1].bar(x - width/2, weekend_comparison['occupancy_rate'], width, \n",
    "              label='Occupancy Rate', alpha=0.8)\n",
    "axes[1,1].bar(x + width/2, weekend_comparison['target_price']/20, width, \n",
    "              label='Price (scaled)', alpha=0.8)\n",
    "axes[1,1].set_title('Weekend vs Weekday Patterns')\n",
    "axes[1,1].set_ylabel('Value')\n",
    "axes[1,1].set_xticks(x)\n",
    "axes[1,1].set_xticklabels(['Weekday', 'Weekend'])\n",
    "axes[1,1].legend()\n",
    "\n",
    "# 6. Correlation heatmap\n",
    "numeric_cols = ['hour', 'day_of_week', 'occupancy_rate', 'queue_length', \n",
    "                'traffic_numeric', 'vehicle_numeric', 'is_rush_hour', 'target_price']\n",
    "correlation_matrix = parking_data[numeric_cols].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            ax=axes[1,2], cbar_kws={'shrink': 0.8})\n",
    "axes[1,2].set_title('Feature Correlations')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n🎯 Key Insights from Your Data:\")\n",
    "print(f\"• Strongest price correlation: {correlation_matrix['target_price'].abs().sort_values(ascending=False).index[1]} ({correlation_matrix['target_price'].abs().sort_values(ascending=False).iloc[1]:.3f})\")\n",
    "print(f\"• Peak occupancy hour: {hourly_avg.idxmax()}:00 ({hourly_avg.max():.1%})\")\n",
    "print(f\"• Highest traffic price: ${traffic_prices.iloc[-1]:.2f} (High traffic)\")\n",
    "print(f\"• Weekend vs weekday price difference: ${abs(weekend_comparison.loc[1, 'target_price'] - weekend_comparison.loc[0, 'target_price']):.2f}\")
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 🤖 Experiment 2: Simple ML Baseline (45 minutes)\n",
    "\n",
    "**Goal**: Build and evaluate a basic machine learning model for price prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Prepare Data for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for modeling from your actual data\n",
    "feature_columns = [\n",
    "    'hour', 'day_of_week', 'is_weekend', 'is_rush_hour',\n",
    "    'occupancy_rate', 'queue_length', 'traffic_numeric', \n",
    "    'vehicle_numeric', 'is_special_day'\n",
    "]\n",
    "\n",
    "target_column = 'target_price'  # Our generated price target\n",
    "\n",
    "# Prepare features and target\n",
    "X = parking_data[feature_columns].copy()\n",
    "y = parking_data[target_column].copy()\n",
    "\n",
    "print(f\"📊 Features shape: {X.shape}\")\n",
    "print(f\"🎯 Target shape: {y.shape}\")\n",
    "print(f\"\\n🔧 Feature columns from your parking data:\")\n",
    "for i, col in enumerate(feature_columns, 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\n✂️ Data Split:\")\n",
    "print(f\"• Training set: {X_train.shape[0]:,} samples\")\n",
    "print(f\"• Testing set: {X_test.shape[0]:,} samples\")\n",
    "print(f\"• Split ratio: {X_test.shape[0]/X.shape[0]:.1%} test\")
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Train Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the model\n",
    "print(\"🔄 Training Linear Regression model...\")\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "print(\"✅ Model training complete!\")\n",
    "\n",
    "# Calculate performance metrics\n",
    "def calculate_metrics(y_true, y_pred, dataset_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n📊 {dataset_name} Performance:\")\n",
    "    print(f\"• MAE (Mean Absolute Error): ${mae:.2f}\")\n",
    "    print(f\"• RMSE (Root Mean Square Error): ${rmse:.2f}\")\n",
    "    print(f\"• R² (Coefficient of Determination): {r2:.3f}\")\n",
    "    \n",
    "    return {'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "# Evaluate on both training and test sets\n",
    "train_metrics = calculate_metrics(y_train, y_train_pred, \"Training Set\")\n",
    "test_metrics = calculate_metrics(y_test, y_test_pred, \"Test Set\")\n",
    "\n",
    "# Check for overfitting\n",
    "overfit_check = train_metrics['R2'] - test_metrics['R2']\n",
    "if overfit_check > 0.1:\n",
    "    print(f\"\\n⚠️ Potential overfitting detected (R² difference: {overfit_check:.3f})\")\n",
    "else:\n",
    "    print(f\"\\n✅ Good generalization (R² difference: {overfit_check:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Analyze Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('🤖 Linear Regression Model Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Actual vs Predicted (Test Set)\n",
    "axes[0,0].scatter(y_test, y_test_pred, alpha=0.6, color='blue')\n",
    "axes[0,0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0,0].set_xlabel('Actual Price ($)')\n",
    "axes[0,0].set_ylabel('Predicted Price ($)')\n",
    "axes[0,0].set_title(f'Actual vs Predicted (R² = {test_metrics[\"R2\"]:.3f})')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Residuals plot\n",
    "residuals = y_test - y_test_pred\n",
    "axes[0,1].scatter(y_test_pred, residuals, alpha=0.6, color='green')\n",
    "axes[0,1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0,1].set_xlabel('Predicted Price ($)')\n",
    "axes[0,1].set_ylabel('Residuals ($)')\n",
    "axes[0,1].set_title('Residuals Plot')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Feature importance (coefficients)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'coefficient': model.coef_\n",
    "}).sort_values('coefficient', key=abs, ascending=True)\n",
    "\n",
    "axes[1,0].barh(range(len(feature_importance)), feature_importance['coefficient'], \n",
    "               color=['red' if x < 0 else 'blue' for x in feature_importance['coefficient']])\n",
    "axes[1,0].set_yticks(range(len(feature_importance)))\n",
    "axes[1,0].set_yticklabels(feature_importance['feature'])\n",
    "axes[1,0].set_xlabel('Coefficient Value')\n",
    "axes[1,0].set_title('Feature Importance (Coefficients)')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Error distribution\n",
    "axes[1,1].hist(residuals, bins=30, alpha=0.7, color='purple')\n",
    "axes[1,1].axvline(x=0, color='r', linestyle='--')\n",
    "axes[1,1].set_xlabel('Prediction Error ($)')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "axes[1,1].set_title(f'Error Distribution (MAE = ${test_metrics[\"MAE\"]:.2f})')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance insights\n",
    "print(\"🎯 Model Insights:\")\n",
    "print(f\"• Most important feature: {feature_importance.iloc[-1]['feature']} (coeff: {feature_importance.iloc[-1]['coefficient']:.3f})\")\n",
    "print(f\"• Least important feature: {feature_importance.iloc[0]['feature']} (coeff: {feature_importance.iloc[0]['coefficient']:.3f})\")\n",
    "print(f\"• Model intercept: ${model.intercept_:.2f}\")\n",
    "print(f\"• Average prediction error: ${test_metrics['MAE']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Test Model with New Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test scenarios using actual feature columns\n",
    "test_scenarios = pd.DataFrame({\n",
    "    'scenario': ['Rush Hour Peak', 'Weekend Casual', 'High Traffic Event', 'Low Demand', 'Special Day'],\n",
    "    'hour': [8, 14, 19, 11, 10],\n",
    "    'day_of_week': [1, 6, 5, 2, 3],  # Monday, Sunday, Saturday, Wednesday, Thursday\n",
    "    'is_weekend': [0, 1, 1, 0, 0],\n",
    "    'is_rush_hour': [1, 0, 1, 0, 0],  # Rush hour flag\n",
    "    'occupancy_rate': [0.85, 0.45, 0.92, 0.25, 0.70],\n",
    "    'queue_length': [8, 2, 12, 1, 5],\n",
    "    'traffic_numeric': [2, 1, 3, 1, 2],  # 1=low, 2=avg, 3=high\n",
    "    'vehicle_numeric': [3, 2, 4, 2, 3],  # 1=cycle, 2=bike, 3=car, 4=truck\n",
    "    'is_special_day': [0, 0, 0, 0, 1]  # Special event flag\n",
    "})\n",
    "\n",
    "# Make predictions for test scenarios\n",
    "scenario_features = test_scenarios[feature_columns]\n",
    "scenario_predictions = model.predict(scenario_features)\n",
    "\n",
    "# Display results\n",
    "results_df = test_scenarios[['scenario']].copy()\n",
    "results_df['predicted_price'] = np.round(scenario_predictions, 2)\n",
    "results_df['occupancy'] = test_scenarios['occupancy_rate']\n",
    "results_df['traffic'] = test_scenarios['traffic_numeric'].map({1: 'Low', 2: 'Average', 3: 'High'})\n",
    "results_df['vehicle'] = test_scenarios['vehicle_numeric'].map({1: 'Cycle', 2: 'Bike', 3: 'Car', 4: 'Truck'})\n",
    "results_df['special_day'] = test_scenarios['is_special_day'].map({0: 'No', 1: 'Yes'})\n",
    "\n",
    "print(\"🧪 Model Predictions for Parking Scenarios:\")\n",
    "print(\"=\" * 60)\n",
    "for idx, row in results_df.iterrows():\n",
    "    print(f\"📍 {row['scenario']}:\")\n",
    "    print(f\"   💰 Predicted Price: ${row['predicted_price']:.2f}\")\n",
    "    print(f\"   📊 Occupancy: {row['occupancy']:.1%}\")\n",
    "    print(f\"   🚗 Vehicle Type: {row['vehicle']}\")\n",
    "    print(f\"   🛣️ Traffic: {row['traffic']}\")\n",
    "    print(f\"   🎆 Special Day: {row['special_day']}\")\n",
    "    print()\n",
    "\n",
    "# Business insights from your data\n",
    "print(\"💡 Business Insights from Your Parking Data:\")\n",
    "highest_price_idx = results_df['predicted_price'].idxmax()\n",
    "lowest_price_idx = results_df['predicted_price'].idxmin()\n",
    "\n",
    "print(f\"• Highest price scenario: {results_df.loc[highest_price_idx, 'scenario']} (${results_df.loc[highest_price_idx, 'predicted_price']:.2f})\")\n",
    "print(f\"• Lowest price scenario: {results_df.loc[lowest_price_idx, 'scenario']} (${results_df.loc[lowest_price_idx, 'predicted_price']:.2f})\")\n",
    "print(f\"• Price range: ${results_df['predicted_price'].min():.2f} - ${results_df['predicted_price'].max():.2f}\")\n",
    "print(f\"• Average predicted price: ${results_df['predicted_price'].mean():.2f}\")\n",
    "print(f\"• Price variation: {((results_df['predicted_price'].max() - results_df['predicted_price'].min()) / results_df['predicted_price'].mean()):.1%}\")
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ⚛️ Experiment 3: Quantum Circuit Simulation (30 minutes)\n",
    "\n",
    "**Goal**: Create and run basic quantum circuits to understand quantum concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Simple Quantum Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple 2-qubit quantum circuit\n",
    "qc = QuantumCircuit(2, 2)\n",
    "\n",
    "# Start with |00⟩ state (both qubits in 0)\n",
    "print(\"🔬 Creating 2-qubit quantum circuit...\")\n",
    "\n",
    "# Apply Hadamard gate to first qubit (creates superposition)\n",
    "qc.h(0)  # Now we have (|00⟩ + |10⟩)/√2\n",
    "\n",
    "# Apply CNOT gate (creates entanglement)\n",
    "qc.cx(0, 1)  # Now we have (|00⟩ + |11⟩)/√2 - Bell state!\n",
    "\n",
    "# Add measurements\n",
    "qc.measure([0, 1], [0, 1])\n",
    "\n",
    "# Display the circuit\n",
    "print(\"\\n📊 Quantum Circuit:\")\n",
    "print(qc)\n",
    "\n",
    "# Visualize the circuit (if possible)\n",
    "try:\n",
    "    qc.draw(output='mpl')\n",
    "    plt.title('Simple Quantum Circuit')\n",
    "    plt.show()\n",
    "except:\n",
    "    print(\"📝 Circuit visualization not available in text mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Run Quantum Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up quantum simulator\n",
    "simulator = Aer.get_backend('qasm_simulator')\n",
    "\n",
    "# Execute the circuit\n",
    "print(\"🔄 Running quantum simulation...\")\n",
    "job = execute(qc, simulator, shots=1000)\n",
    "result = job.result()\n",
    "counts = result.get_counts(qc)\n",
    "\n",
    "print(f\"✅ Simulation complete! (1000 shots)\")\n",
    "print(f\"\\n📊 Measurement Results:\")\n",
    "for state, count in sorted(counts.items()):\n",
    "    probability = count / 1000\n",
    "    print(f\"• State |{state}⟩: {count:3d} times ({probability:.1%})\")\n",
    "\n",
    "# Visualize results\n",
    "try:\n",
    "    plot_histogram(counts)\n",
    "    plt.title('Quantum Measurement Results')\n",
    "    plt.show()\n",
    "except:\n",
    "    # Manual bar plot if qiskit visualization fails\n",
    "    states = list(counts.keys())\n",
    "    frequencies = list(counts.values())\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(states, frequencies, color='skyblue', alpha=0.8)\n",
    "    plt.xlabel('Quantum State')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Quantum Measurement Results (Bell State)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add probability labels\n",
    "    for i, (state, freq) in enumerate(zip(states, frequencies)):\n",
    "        plt.text(i, freq + 10, f'{freq/1000:.1%}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Explain the results\n",
    "print(\"\\n🧠 Understanding the Results:\")\n",
    "print(\"• We created a 'Bell State' - maximum entanglement between qubits\")\n",
    "print(\"• Expected: 50% |00⟩ and 50% |11⟩ (never |01⟩ or |10⟩)\")\n",
    "if '01' in counts or '10' in counts:\n",
    "    error_rate = (counts.get('01', 0) + counts.get('10', 0)) / 1000\n",
    "    print(f\"• Small error rate: {error_rate:.1%} (due to quantum noise simulation)\")\n",
    "else:\n",
    "    print(\"• Perfect entanglement observed! 🎉\")\n",
    "    \n",
    "print(\"• This demonstrates quantum superposition and entanglement!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Quantum Feature Encoding Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple quantum feature encoding for parking data\n",
    "def encode_parking_features(occupancy_rate, queue_length):\n",
    "    \"\"\"\n",
    "    Encode parking features into quantum circuit\n",
    "    \n",
    "    - occupancy_rate: encoded as rotation angle\n",
    "    - queue_length: encoded as conditional gates\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create 2-qubit circuit\n",
    "    qc = QuantumCircuit(2, 2)\n",
    "    \n",
    "    # Encode occupancy as rotation (0.0 → 0°, 1.0 → π)\n",
    "    occupancy_angle = occupancy_rate * np.pi\n",
    "    qc.ry(occupancy_angle, 0)\n",
    "    \n",
    "    # Encode queue length as conditional operations\n",
    "    if queue_length > 5:  # High queue\n",
    "        qc.x(1)  # Flip second qubit\n",
    "    if queue_length > 10:  # Very high queue\n",
    "        qc.cx(0, 1)  # Add entanglement\n",
    "    \n",
    "    # Measure\n",
    "    qc.measure([0, 1], [0, 1])\n",
    "    \n",
    "    return qc\n",
    "\n",
    "# Test with different parking scenarios\n",
    "scenarios = [\n",
    "    {\"name\": \"Low Demand\", \"occupancy\": 0.2, \"queue\": 1},\n",
    "    {\"name\": \"Medium Demand\", \"occupancy\": 0.6, \"queue\": 5},\n",
    "    {\"name\": \"High Demand\", \"occupancy\": 0.9, \"queue\": 12}\n",
    "]\n",
    "\n",
    "print(\"🧪 Quantum Feature Encoding Experiment:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "for scenario in scenarios:\n",
    "    print(f\"\\n📍 Scenario: {scenario['name']}\")\n",
    "    print(f\"   Occupancy: {scenario['occupancy']:.1%}\")\n",
    "    print(f\"   Queue Length: {scenario['queue']}\")\n",
    "    \n",
    "    # Create quantum circuit for this scenario\n",
    "    qc_scenario = encode_parking_features(scenario['occupancy'], scenario['queue'])\n",
    "    \n",
    "    # Run simulation\n",
    "    job = execute(qc_scenario, simulator, shots=100)\n",
    "    result = job.result()\n",
    "    counts = result.get_counts(qc_scenario)\n",
    "    \n",
    "    # Calculate quantum \"price signal\"\n",
    "    # Higher probability of |11⟩ → higher price\n",
    "    prob_11 = counts.get('11', 0) / 100\n",
    "    quantum_price_signal = prob_11\n",
    "    \n",
    "    print(f\"   Quantum States: {dict(counts)}\")\n",
    "    print(f\"   Quantum Price Signal: {quantum_price_signal:.2f}\")\n",
    "    \n",
    "    results_summary.append({\n",
    "        'scenario': scenario['name'],\n",
    "        'occupancy': scenario['occupancy'],\n",
    "        'queue': scenario['queue'],\n",
    "        'quantum_signal': quantum_price_signal,\n",
    "        'states': dict(counts)\n",
    "    })\n",
    "\n",
    "# Compare quantum signals\n",
    "print(\"\\n📊 Quantum Signal Comparison:\")\n",
    "scenarios_df = pd.DataFrame(results_summary)\n",
    "scenarios_df = scenarios_df.sort_values('quantum_signal')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(scenarios_df['scenario'], scenarios_df['quantum_signal'], \n",
    "               color=['green', 'orange', 'red'], alpha=0.7)\n",
    "plt.ylabel('Quantum Price Signal')\n",
    "plt.title('Quantum Feature Encoding Results')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, scenarios_df['quantum_signal']):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{value:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n🎯 Quantum Encoding Insights:\")\n",
    "print(f\"• Lowest signal: {scenarios_df.iloc[0]['scenario']} ({scenarios_df.iloc[0]['quantum_signal']:.2f})\")\n",
    "print(f\"• Highest signal: {scenarios_df.iloc[-1]['scenario']} ({scenarios_df.iloc[-1]['quantum_signal']:.2f})\")\n",
    "print(\"• Quantum circuits can encode multiple features simultaneously!\")\n",
    "print(\"• Next week: We'll use this for actual quantum machine learning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 📝 Week 1 Summary & Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 What We Learned\n",
    "\n",
    "### **Machine Learning Concepts:**\n",
    "1. **Problem Formulation**: Parking pricing as regression problem\n",
    "2. **Feature Engineering**: Time, location, demand, and external factors\n",
    "3. **Model Training**: Linear regression baseline\n",
    "4. **Evaluation Metrics**: MAE, RMSE, R² for business context\n",
    "5. **Model Interpretation**: Feature importance and business insights\n",
    "\n",
    "### **Quantum Computing Concepts:**\n",
    "1. **Quantum States**: Superposition and entanglement\n",
    "2. **Quantum Gates**: H, X, CNOT for quantum operations\n",
    "3. **Measurement**: Probabilistic outcomes\n",
    "4. **Feature Encoding**: Mapping classical data to quantum states\n",
    "5. **Quantum Advantage**: Parallel processing potential\n",
    "\n",
    "## 🔍 Key Findings\n",
    "\n",
    "### **From Our Data:**\n",
    "- Occupancy rate is the strongest price predictor\n",
    "- Rush hours and events significantly impact pricing\n",
    "- Location differences create price premiums\n",
    "- Weather and queue length provide additional signals\n",
    "\n",
    "### **From Our Models:**\n",
    "- Linear regression achieved reasonable baseline performance\n",
    "- Model generalizes well (no severe overfitting)\n",
    "- Feature importance aligns with business intuition\n",
    "- Room for improvement with more complex models\n",
    "\n",
    "### **From Quantum Experiments:**\n",
    "- Successfully created and measured quantum states\n",
    "- Demonstrated entanglement with Bell states\n",
    "- Encoded parking features into quantum circuits\n",
    "- Different scenarios produce distinct quantum signatures\n",
    "\n",
    "## 🚀 Next Week Preparation\n",
    "\n",
    "**Questions to Explore:**\n",
    "1. How can quantum circuits improve upon classical ML?\n",
    "2. What quantum algorithms are best for pricing optimization?\n",
    "3. How do we measure quantum advantage quantitatively?\n",
    "\n",
    "**Skills to Develop:**\n",
    "1. Variational quantum circuits (VQC)\n",
    "2. Quantum feature maps\n",
    "3. Hybrid quantum-classical optimization\n",
    "4. Performance benchmarking\n",
    "\n",
    "Ready for Week 2? Let's dive deeper into quantum machine learning! 🎉"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
