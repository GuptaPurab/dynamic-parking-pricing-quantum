{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧪 Week 1 Experiments: ML & Quantum Fundamentals\n",
    "\n",
    "**Objective**: Hands-on exploration of machine learning and quantum computing concepts\n",
    "\n",
    "**Time Allocation**: 2 hours total\n",
    "- Experiment 1: Data Exploration (45 mins)\n",
    "- Experiment 2: Simple ML Baseline (45 mins) \n",
    "- Experiment 3: Quantum Circuit Simulation (30 mins)\n",
    "\n",
    "**Learning Goals**:\n",
    "- Understand parking data characteristics\n",
    "- Build your first ML pricing model\n",
    "- Create and run quantum circuits\n",
    "- Connect theory to practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Quantum Computing\n",
    "from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister\n",
    "from qiskit import execute, Aer\n",
    "from qiskit.visualization import plot_histogram, plot_circuit_layout\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display settings\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✅ All imports successful!\")\n",
    "print(f\"📊 NumPy: {np.__version__}\")\n",
    "print(f\"🐼 Pandas: {pd.__version__}\")\n",
    "print(f\"🚀 Ready to explore!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 🔍 Experiment 1: Data Exploration (45 minutes)\n",
    "\n",
    "**Goal**: Understand parking data patterns and create synthetic dataset for learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Create Synthetic Parking Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_parking_data(n_samples=1000, n_locations=5):\n",
    "    \"\"\"\n",
    "    Generate synthetic parking data with realistic patterns\n",
    "    \n",
    "    Features:\n",
    "    - Temporal: hour, day_of_week, is_weekend\n",
    "    - Demand: occupancy_rate, queue_length  \n",
    "    - External: weather_score, event_factor\n",
    "    - Location: location_id, base_price\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate time-based features\n",
    "    hours = np.random.randint(6, 23, n_samples)  # 6 AM to 10 PM\n",
    "    days = np.random.randint(0, 7, n_samples)    # Monday=0 to Sunday=6\n",
    "    is_weekend = (days >= 5).astype(int)\n",
    "    \n",
    "    # Generate location data\n",
    "    location_ids = np.random.randint(0, n_locations, n_samples)\n",
    "    location_names = [f\"Zone_{i}\" for i in range(n_locations)]\n",
    "    \n",
    "    # Create demand patterns based on time\n",
    "    # Rush hours (8-9 AM, 5-7 PM) have higher demand\n",
    "    rush_hour_morning = ((hours >= 8) & (hours <= 9)).astype(int)\n",
    "    rush_hour_evening = ((hours >= 17) & (hours <= 19)).astype(int)\n",
    "    \n",
    "    # Base occupancy influenced by time patterns\n",
    "    base_occupancy = 0.3 + 0.4 * (rush_hour_morning + rush_hour_evening)\n",
    "    \n",
    "    # Add weekend effects (different patterns)\n",
    "    weekend_effect = is_weekend * 0.2 * np.random.normal(0, 1, n_samples)\n",
    "    \n",
    "    # Final occupancy with noise\n",
    "    occupancy_rate = np.clip(\n",
    "        base_occupancy + weekend_effect + np.random.normal(0, 0.15, n_samples),\n",
    "        0.05, 0.95\n",
    "    )\n",
    "    \n",
    "    # Queue length correlated with occupancy\n",
    "    queue_length = np.maximum(0, \n",
    "        np.round(5 * occupancy_rate + np.random.exponential(1, n_samples))\n",
    "    ).astype(int)\n",
    "    \n",
    "    # External factors\n",
    "    weather_score = np.random.uniform(0.3, 1.0, n_samples)  # 1.0 = perfect weather\n",
    "    event_factor = np.random.choice([0, 1], n_samples, p=[0.85, 0.15])  # 15% chance of events\n",
    "    \n",
    "    # Generate prices based on demand (this is what we want to predict/optimize)\n",
    "    base_prices = np.array([8, 10, 12, 15, 18])  # Different zones have different base prices\n",
    "    zone_base_price = base_prices[location_ids]\n",
    "    \n",
    "    # Price influenced by occupancy, time, and external factors\n",
    "    price_multiplier = (\n",
    "        1.0 +                                    # Base\n",
    "        0.8 * occupancy_rate +                   # Occupancy effect\n",
    "        0.3 * (rush_hour_morning + rush_hour_evening) +  # Rush hour premium\n",
    "        0.2 * event_factor +                     # Event premium\n",
    "        0.1 * (1 - weather_score)                # Bad weather premium\n",
    "    )\n",
    "    \n",
    "    optimal_price = zone_base_price * price_multiplier\n",
    "    \n",
    "    # Create DataFrame\n",
    "    data = pd.DataFrame({\n",
    "        'location_id': location_ids,\n",
    "        'location_name': [location_names[i] for i in location_ids],\n",
    "        'hour': hours,\n",
    "        'day_of_week': days,\n",
    "        'is_weekend': is_weekend,\n",
    "        'occupancy_rate': np.round(occupancy_rate, 3),\n",
    "        'queue_length': queue_length,\n",
    "        'weather_score': np.round(weather_score, 2),\n",
    "        'event_factor': event_factor,\n",
    "        'base_price': zone_base_price,\n",
    "        'optimal_price': np.round(optimal_price, 2)\n",
    "    })\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Generate our dataset\n",
    "print(\"🔄 Generating synthetic parking data...\")\n",
    "parking_data = generate_parking_data(n_samples=2000, n_locations=5)\n",
    "print(f\"✅ Generated {len(parking_data)} parking records\")\n",
    "print(f\"📊 Shape: {parking_data.shape}\")\n",
    "\n",
    "# Display first few rows\n",
    "parking_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"📈 Dataset Overview:\")\n",
    "print(f\"Total samples: {len(parking_data)}\")\n",
    "print(f\"Features: {len(parking_data.columns)}\")\n",
    "print(f\"Locations: {parking_data['location_name'].nunique()}\")\n",
    "print(f\"Price range: ${parking_data['optimal_price'].min():.2f} - ${parking_data['optimal_price'].max():.2f}\")\n",
    "print(f\"Avg occupancy: {parking_data['occupancy_rate'].mean():.1%}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\n🔍 Missing Values:\")\n",
    "print(parking_data.isnull().sum())\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\n📊 Statistical Summary:\")\n",
    "parking_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('🔍 Parking Data Exploration', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Price distribution\n",
    "axes[0,0].hist(parking_data['optimal_price'], bins=30, alpha=0.7, color='skyblue')\n",
    "axes[0,0].set_title('Price Distribution')\n",
    "axes[0,0].set_xlabel('Price ($)')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "\n",
    "# 2. Occupancy vs Price\n",
    "axes[0,1].scatter(parking_data['occupancy_rate'], parking_data['optimal_price'], \n",
    "                  alpha=0.6, color='coral')\n",
    "axes[0,1].set_title('Occupancy vs Price')\n",
    "axes[0,1].set_xlabel('Occupancy Rate')\n",
    "axes[0,1].set_ylabel('Price ($)')\n",
    "\n",
    "# 3. Hourly demand patterns\n",
    "hourly_avg = parking_data.groupby('hour')['occupancy_rate'].mean()\n",
    "axes[0,2].plot(hourly_avg.index, hourly_avg.values, marker='o', color='green')\n",
    "axes[0,2].set_title('Average Occupancy by Hour')\n",
    "axes[0,2].set_xlabel('Hour of Day')\n",
    "axes[0,2].set_ylabel('Avg Occupancy Rate')\n",
    "axes[0,2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Price by location\n",
    "location_prices = parking_data.groupby('location_name')['optimal_price'].mean().sort_values()\n",
    "axes[1,0].bar(range(len(location_prices)), location_prices.values, color='purple', alpha=0.7)\n",
    "axes[1,0].set_title('Average Price by Location')\n",
    "axes[1,0].set_xlabel('Location')\n",
    "axes[1,0].set_ylabel('Avg Price ($)')\n",
    "axes[1,0].set_xticks(range(len(location_prices)))\n",
    "axes[1,0].set_xticklabels(location_prices.index, rotation=45)\n",
    "\n",
    "# 5. Weekend vs Weekday\n",
    "weekend_comparison = parking_data.groupby('is_weekend')[['occupancy_rate', 'optimal_price']].mean()\n",
    "x = np.arange(2)\n",
    "width = 0.35\n",
    "axes[1,1].bar(x - width/2, weekend_comparison['occupancy_rate'], width, \n",
    "              label='Occupancy Rate', alpha=0.8)\n",
    "axes[1,1].bar(x + width/2, weekend_comparison['optimal_price']/20, width, \n",
    "              label='Price (scaled)', alpha=0.8)\n",
    "axes[1,1].set_title('Weekend vs Weekday Patterns')\n",
    "axes[1,1].set_ylabel('Value')\n",
    "axes[1,1].set_xticks(x)\n",
    "axes[1,1].set_xticklabels(['Weekday', 'Weekend'])\n",
    "axes[1,1].legend()\n",
    "\n",
    "# 6. Correlation heatmap\n",
    "numeric_cols = ['hour', 'day_of_week', 'occupancy_rate', 'queue_length', \n",
    "                'weather_score', 'event_factor', 'optimal_price']\n",
    "correlation_matrix = parking_data[numeric_cols].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            ax=axes[1,2], cbar_kws={'shrink': 0.8})\n",
    "axes[1,2].set_title('Feature Correlations')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n🎯 Key Insights:\")\n",
    "print(f\"• Strongest price correlation: {correlation_matrix['optimal_price'].abs().sort_values(ascending=False).index[1]} ({correlation_matrix['optimal_price'].abs().sort_values(ascending=False).iloc[1]:.3f})\")\n",
    "print(f\"• Peak occupancy hour: {hourly_avg.idxmax()}:00 ({hourly_avg.max():.1%})\")\n",
    "print(f\"• Most expensive location: {location_prices.index[-1]} (${location_prices.iloc[-1]:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 🤖 Experiment 2: Simple ML Baseline (45 minutes)\n",
    "\n",
    "**Goal**: Build and evaluate a basic machine learning model for price prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Prepare Data for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for modeling\n",
    "feature_columns = [\n",
    "    'hour', 'day_of_week', 'is_weekend',\n",
    "    'occupancy_rate', 'queue_length', \n",
    "    'weather_score', 'event_factor',\n",
    "    'location_id'  # We'll use location as a categorical feature\n",
    "]\n",
    "\n",
    "target_column = 'optimal_price'\n",
    "\n",
    "# Prepare features and target\n",
    "X = parking_data[feature_columns].copy()\n",
    "y = parking_data[target_column].copy()\n",
    "\n",
    "print(f\"📊 Features shape: {X.shape}\")\n",
    "print(f\"🎯 Target shape: {y.shape}\")\n",
    "print(f\"\\n🔧 Feature columns:\")\n",
    "for i, col in enumerate(feature_columns, 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=X['location_id']\n",
    ")\n",
    "\n",
    "print(f\"\\n✂️ Data Split:\")\n",
    "print(f\"• Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"• Testing set: {X_test.shape[0]} samples\")\n",
    "print(f\"• Split ratio: {X_test.shape[0]/X.shape[0]:.1%} test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Train Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the model\n",
    "print(\"🔄 Training Linear Regression model...\")\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "print(\"✅ Model training complete!\")\n",
    "\n",
    "# Calculate performance metrics\n",
    "def calculate_metrics(y_true, y_pred, dataset_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n📊 {dataset_name} Performance:\")\n",
    "    print(f\"• MAE (Mean Absolute Error): ${mae:.2f}\")\n",
    "    print(f\"• RMSE (Root Mean Square Error): ${rmse:.2f}\")\n",
    "    print(f\"• R² (Coefficient of Determination): {r2:.3f}\")\n",
    "    \n",
    "    return {'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "# Evaluate on both training and test sets\n",
    "train_metrics = calculate_metrics(y_train, y_train_pred, \"Training Set\")\n",
    "test_metrics = calculate_metrics(y_test, y_test_pred, \"Test Set\")\n",
    "\n",
    "# Check for overfitting\n",
    "overfit_check = train_metrics['R2'] - test_metrics['R2']\n",
    "if overfit_check > 0.1:\n",
    "    print(f\"\\n⚠️ Potential overfitting detected (R² difference: {overfit_check:.3f})\")\n",
    "else:\n",
    "    print(f\"\\n✅ Good generalization (R² difference: {overfit_check:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Analyze Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('🤖 Linear Regression Model Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Actual vs Predicted (Test Set)\n",
    "axes[0,0].scatter(y_test, y_test_pred, alpha=0.6, color='blue')\n",
    "axes[0,0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0,0].set_xlabel('Actual Price ($)')\n",
    "axes[0,0].set_ylabel('Predicted Price ($)')\n",
    "axes[0,0].set_title(f'Actual vs Predicted (R² = {test_metrics[\"R2\"]:.3f})')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Residuals plot\n",
    "residuals = y_test - y_test_pred\n",
    "axes[0,1].scatter(y_test_pred, residuals, alpha=0.6, color='green')\n",
    "axes[0,1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0,1].set_xlabel('Predicted Price ($)')\n",
    "axes[0,1].set_ylabel('Residuals ($)')\n",
    "axes[0,1].set_title('Residuals Plot')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Feature importance (coefficients)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'coefficient': model.coef_\n",
    "}).sort_values('coefficient', key=abs, ascending=True)\n",
    "\n",
    "axes[1,0].barh(range(len(feature_importance)), feature_importance['coefficient'], \n",
    "               color=['red' if x < 0 else 'blue' for x in feature_importance['coefficient']])\n",
    "axes[1,0].set_yticks(range(len(feature_importance)))\n",
    "axes[1,0].set_yticklabels(feature_importance['feature'])\n",
    "axes[1,0].set_xlabel('Coefficient Value')\n",
    "axes[1,0].set_title('Feature Importance (Coefficients)')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Error distribution\n",
    "axes[1,1].hist(residuals, bins=30, alpha=0.7, color='purple')\n",
    "axes[1,1].axvline(x=0, color='r', linestyle='--')\n",
    "axes[1,1].set_xlabel('Prediction Error ($)')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "axes[1,1].set_title(f'Error Distribution (MAE = ${test_metrics[\"MAE\"]:.2f})')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance insights\n",
    "print(\"🎯 Model Insights:\")\n",
    "print(f\"• Most important feature: {feature_importance.iloc[-1]['feature']} (coeff: {feature_importance.iloc[-1]['coefficient']:.3f})\")\n",
    "print(f\"• Least important feature: {feature_importance.iloc[0]['feature']} (coeff: {feature_importance.iloc[0]['coefficient']:.3f})\")\n",
    "print(f\"• Model intercept: ${model.intercept_:.2f}\")\n",
    "print(f\"• Average prediction error: ${test_metrics['MAE']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Test Model with New Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test scenarios\n",
    "test_scenarios = pd.DataFrame({\n",
    "    'scenario': ['Rush Hour Peak', 'Weekend Casual', 'Event Day', 'Low Demand', 'Bad Weather'],\n",
    "    'hour': [8, 14, 19, 11, 16],\n",
    "    'day_of_week': [1, 6, 5, 2, 3],  # Monday, Sunday, Saturday, Wednesday, Thursday\n",
    "    'is_weekend': [0, 1, 1, 0, 0],\n",
    "    'occupancy_rate': [0.85, 0.45, 0.92, 0.25, 0.60],\n",
    "    'queue_length': [8, 2, 12, 1, 4],\n",
    "    'weather_score': [0.9, 0.8, 0.9, 0.7, 0.3],  # 0.3 = bad weather\n",
    "    'event_factor': [0, 0, 1, 0, 0],\n",
    "    'location_id': [2, 1, 4, 0, 3]  # Different zones\n",
    "})\n",
    "\n",
    "# Make predictions for test scenarios\n",
    "scenario_features = test_scenarios[feature_columns]\n",
    "scenario_predictions = model.predict(scenario_features)\n",
    "\n",
    "# Display results\n",
    "results_df = test_scenarios[['scenario']].copy()\n",
    "results_df['predicted_price'] = np.round(scenario_predictions, 2)\n",
    "results_df['occupancy'] = test_scenarios['occupancy_rate']\n",
    "results_df['weather'] = test_scenarios['weather_score']\n",
    "results_df['event'] = test_scenarios['event_factor'].map({0: 'No', 1: 'Yes'})\n",
    "\n",
    "print(\"🧪 Model Predictions for Test Scenarios:\")\n",
    "print(\"=\" * 60)\n",
    "for idx, row in results_df.iterrows():\n",
    "    print(f\"📍 {row['scenario']}:\")\n",
    "    print(f\"   💰 Predicted Price: ${row['predicted_price']:.2f}\")\n",
    "    print(f\"   📊 Occupancy: {row['occupancy']:.1%}\")\n",
    "    print(f\"   🌤️ Weather: {row['weather']:.1f}/1.0\")\n",
    "    print(f\"   🎉 Event: {row['event']}\")\n",
    "    print()\n",
    "\n",
    "# Business insights\n",
    "print(\"💡 Business Insights:\")\n",
    "highest_price_idx = results_df['predicted_price'].idxmax()\n",
    "lowest_price_idx = results_df['predicted_price'].idxmin()\n",
    "\n",
    "print(f\"• Highest price scenario: {results_df.loc[highest_price_idx, 'scenario']} (${results_df.loc[highest_price_idx, 'predicted_price']:.2f})\")\n",
    "print(f\"• Lowest price scenario: {results_df.loc[lowest_price_idx, 'scenario']} (${results_df.loc[lowest_price_idx, 'predicted_price']:.2f})\")\n",
    "print(f\"• Price range: ${results_df['predicted_price'].min():.2f} - ${results_df['predicted_price'].max():.2f}\")\n",
    "print(f\"• Average predicted price: ${results_df['predicted_price'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ⚛️ Experiment 3: Quantum Circuit Simulation (30 minutes)\n",
    "\n",
    "**Goal**: Create and run basic quantum circuits to understand quantum concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Simple Quantum Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple 2-qubit quantum circuit\n",
    "qc = QuantumCircuit(2, 2)\n",
    "\n",
    "# Start with |00⟩ state (both qubits in 0)\n",
    "print(\"🔬 Creating 2-qubit quantum circuit...\")\n",
    "\n",
    "# Apply Hadamard gate to first qubit (creates superposition)\n",
    "qc.h(0)  # Now we have (|00⟩ + |10⟩)/√2\n",
    "\n",
    "# Apply CNOT gate (creates entanglement)\n",
    "qc.cx(0, 1)  # Now we have (|00⟩ + |11⟩)/√2 - Bell state!\n",
    "\n",
    "# Add measurements\n",
    "qc.measure([0, 1], [0, 1])\n",
    "\n",
    "# Display the circuit\n",
    "print(\"\\n📊 Quantum Circuit:\")\n",
    "print(qc)\n",
    "\n",
    "# Visualize the circuit (if possible)\n",
    "try:\n",
    "    qc.draw(output='mpl')\n",
    "    plt.title('Simple Quantum Circuit')\n",
    "    plt.show()\n",
    "except:\n",
    "    print(\"📝 Circuit visualization not available in text mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Run Quantum Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up quantum simulator\n",
    "simulator = Aer.get_backend('qasm_simulator')\n",
    "\n",
    "# Execute the circuit\n",
    "print(\"🔄 Running quantum simulation...\")\n",
    "job = execute(qc, simulator, shots=1000)\n",
    "result = job.result()\n",
    "counts = result.get_counts(qc)\n",
    "\n",
    "print(f\"✅ Simulation complete! (1000 shots)\")\n",
    "print(f\"\\n📊 Measurement Results:\")\n",
    "for state, count in sorted(counts.items()):\n",
    "    probability = count / 1000\n",
    "    print(f\"• State |{state}⟩: {count:3d} times ({probability:.1%})\")\n",
    "\n",
    "# Visualize results\n",
    "try:\n",
    "    plot_histogram(counts)\n",
    "    plt.title('Quantum Measurement Results')\n",
    "    plt.show()\n",
    "except:\n",
    "    # Manual bar plot if qiskit visualization fails\n",
    "    states = list(counts.keys())\n",
    "    frequencies = list(counts.values())\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(states, frequencies, color='skyblue', alpha=0.8)\n",
    "    plt.xlabel('Quantum State')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Quantum Measurement Results (Bell State)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add probability labels\n",
    "    for i, (state, freq) in enumerate(zip(states, frequencies)):\n",
    "        plt.text(i, freq + 10, f'{freq/1000:.1%}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Explain the results\n",
    "print(\"\\n🧠 Understanding the Results:\")\n",
    "print(\"• We created a 'Bell State' - maximum entanglement between qubits\")\n",
    "print(\"• Expected: 50% |00⟩ and 50% |11⟩ (never |01⟩ or |10⟩)\")\n",
    "if '01' in counts or '10' in counts:\n",
    "    error_rate = (counts.get('01', 0) + counts.get('10', 0)) / 1000\n",
    "    print(f\"• Small error rate: {error_rate:.1%} (due to quantum noise simulation)\")\n",
    "else:\n",
    "    print(\"• Perfect entanglement observed! 🎉\")\n",
    "    \n",
    "print(\"• This demonstrates quantum superposition and entanglement!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Quantum Feature Encoding Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple quantum feature encoding for parking data\n",
    "def encode_parking_features(occupancy_rate, queue_length):\n",
    "    \"\"\"\n",
    "    Encode parking features into quantum circuit\n",
    "    \n",
    "    - occupancy_rate: encoded as rotation angle\n",
    "    - queue_length: encoded as conditional gates\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create 2-qubit circuit\n",
    "    qc = QuantumCircuit(2, 2)\n",
    "    \n",
    "    # Encode occupancy as rotation (0.0 → 0°, 1.0 → π)\n",
    "    occupancy_angle = occupancy_rate * np.pi\n",
    "    qc.ry(occupancy_angle, 0)\n",
    "    \n",
    "    # Encode queue length as conditional operations\n",
    "    if queue_length > 5:  # High queue\n",
    "        qc.x(1)  # Flip second qubit\n",
    "    if queue_length > 10:  # Very high queue\n",
    "        qc.cx(0, 1)  # Add entanglement\n",
    "    \n",
    "    # Measure\n",
    "    qc.measure([0, 1], [0, 1])\n",
    "    \n",
    "    return qc\n",
    "\n",
    "# Test with different parking scenarios\n",
    "scenarios = [\n",
    "    {\"name\": \"Low Demand\", \"occupancy\": 0.2, \"queue\": 1},\n",
    "    {\"name\": \"Medium Demand\", \"occupancy\": 0.6, \"queue\": 5},\n",
    "    {\"name\": \"High Demand\", \"occupancy\": 0.9, \"queue\": 12}\n",
    "]\n",
    "\n",
    "print(\"🧪 Quantum Feature Encoding Experiment:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "for scenario in scenarios:\n",
    "    print(f\"\\n📍 Scenario: {scenario['name']}\")\n",
    "    print(f\"   Occupancy: {scenario['occupancy']:.1%}\")\n",
    "    print(f\"   Queue Length: {scenario['queue']}\")\n",
    "    \n",
    "    # Create quantum circuit for this scenario\n",
    "    qc_scenario = encode_parking_features(scenario['occupancy'], scenario['queue'])\n",
    "    \n",
    "    # Run simulation\n",
    "    job = execute(qc_scenario, simulator, shots=100)\n",
    "    result = job.result()\n",
    "    counts = result.get_counts(qc_scenario)\n",
    "    \n",
    "    # Calculate quantum \"price signal\"\n",
    "    # Higher probability of |11⟩ → higher price\n",
    "    prob_11 = counts.get('11', 0) / 100\n",
    "    quantum_price_signal = prob_11\n",
    "    \n",
    "    print(f\"   Quantum States: {dict(counts)}\")\n",
    "    print(f\"   Quantum Price Signal: {quantum_price_signal:.2f}\")\n",
    "    \n",
    "    results_summary.append({\n",
    "        'scenario': scenario['name'],\n",
    "        'occupancy': scenario['occupancy'],\n",
    "        'queue': scenario['queue'],\n",
    "        'quantum_signal': quantum_price_signal,\n",
    "        'states': dict(counts)\n",
    "    })\n",
    "\n",
    "# Compare quantum signals\n",
    "print(\"\\n📊 Quantum Signal Comparison:\")\n",
    "scenarios_df = pd.DataFrame(results_summary)\n",
    "scenarios_df = scenarios_df.sort_values('quantum_signal')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(scenarios_df['scenario'], scenarios_df['quantum_signal'], \n",
    "               color=['green', 'orange', 'red'], alpha=0.7)\n",
    "plt.ylabel('Quantum Price Signal')\n",
    "plt.title('Quantum Feature Encoding Results')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, scenarios_df['quantum_signal']):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{value:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n🎯 Quantum Encoding Insights:\")\n",
    "print(f\"• Lowest signal: {scenarios_df.iloc[0]['scenario']} ({scenarios_df.iloc[0]['quantum_signal']:.2f})\")\n",
    "print(f\"• Highest signal: {scenarios_df.iloc[-1]['scenario']} ({scenarios_df.iloc[-1]['quantum_signal']:.2f})\")\n",
    "print(\"• Quantum circuits can encode multiple features simultaneously!\")\n",
    "print(\"• Next week: We'll use this for actual quantum machine learning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 📝 Week 1 Summary & Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 What We Learned\n",
    "\n",
    "### **Machine Learning Concepts:**\n",
    "1. **Problem Formulation**: Parking pricing as regression problem\n",
    "2. **Feature Engineering**: Time, location, demand, and external factors\n",
    "3. **Model Training**: Linear regression baseline\n",
    "4. **Evaluation Metrics**: MAE, RMSE, R² for business context\n",
    "5. **Model Interpretation**: Feature importance and business insights\n",
    "\n",
    "### **Quantum Computing Concepts:**\n",
    "1. **Quantum States**: Superposition and entanglement\n",
    "2. **Quantum Gates**: H, X, CNOT for quantum operations\n",
    "3. **Measurement**: Probabilistic outcomes\n",
    "4. **Feature Encoding**: Mapping classical data to quantum states\n",
    "5. **Quantum Advantage**: Parallel processing potential\n",
    "\n",
    "## 🔍 Key Findings\n",
    "\n",
    "### **From Our Data:**\n",
    "- Occupancy rate is the strongest price predictor\n",
    "- Rush hours and events significantly impact pricing\n",
    "- Location differences create price premiums\n",
    "- Weather and queue length provide additional signals\n",
    "\n",
    "### **From Our Models:**\n",
    "- Linear regression achieved reasonable baseline performance\n",
    "- Model generalizes well (no severe overfitting)\n",
    "- Feature importance aligns with business intuition\n",
    "- Room for improvement with more complex models\n",
    "\n",
    "### **From Quantum Experiments:**\n",
    "- Successfully created and measured quantum states\n",
    "- Demonstrated entanglement with Bell states\n",
    "- Encoded parking features into quantum circuits\n",
    "- Different scenarios produce distinct quantum signatures\n",
    "\n",
    "## 🚀 Next Week Preparation\n",
    "\n",
    "**Questions to Explore:**\n",
    "1. How can quantum circuits improve upon classical ML?\n",
    "2. What quantum algorithms are best for pricing optimization?\n",
    "3. How do we measure quantum advantage quantitatively?\n",
    "\n",
    "**Skills to Develop:**\n",
    "1. Variational quantum circuits (VQC)\n",
    "2. Quantum feature maps\n",
    "3. Hybrid quantum-classical optimization\n",
    "4. Performance benchmarking\n",
    "\n",
    "Ready for Week 2? Let's dive deeper into quantum machine learning! 🎉"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
