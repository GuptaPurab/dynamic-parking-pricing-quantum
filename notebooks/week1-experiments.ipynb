{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß™ Week 1 Experiments: Dynamic Parking with Your Data\n",
    "\n",
    "This notebook analyzes your actual parking dataset (`dataset.csv`) to build foundational understanding for our quantum ML project.\n",
    "\n",
    "## üéØ Your Dataset Overview\n",
    "- **18,369 records** from parking system `BHMBCCMKT01`\n",
    "- **Location**: Guwahati, India (26.14¬∞N, 91.73¬∞E)\n",
    "- **Capacity**: 577 parking spaces\n",
    "- **Features**: Occupancy, VehicleType, TrafficCondition, QueueLength, SpecialDays\n",
    "- **Time Range**: October 2016 with hourly updates\n",
    "\n",
    "## üß† Learning Objectives\n",
    "1. **Analyze** your real parking data patterns\n",
    "2. **Engineer** features for time series prediction\n",
    "3. **Build** a classical ML baseline for price prediction\n",
    "4. **Explore** quantum computing fundamentals\n",
    "5. **Design** quantum feature encoding for your parking data\n",
    "\n",
    "## ‚öôÔ∏è Setup & Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Quantum Computing\n",
    "from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister\n",
    "from qiskit import execute, Aer\n",
    "from qiskit.visualization import plot_histogram, plot_circuit_layout\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display settings\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(f\"üìä NumPy: {np.__version__}\")\n",
    "print(f\"üêº Pandas: {pd.__version__}\")\n",
    "print(f\"üöÄ Ready to explore!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üîç Experiment 1: Your Real Data Analysis (45 minutes)\n",
    "\n",
    "**Goal**: Analyze your actual parking dataset and understand patterns for quantum ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load Your Actual Parking Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your actual parking dataset\n",
    "print(\"üìÇ Loading your parking dataset...\")\n",
    "parking_raw = pd.read_csv('../dataset.csv')\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(parking_raw):,} records from BHMBCCMKT01 parking system\")\n",
    "print(f\"üìä Raw data shape: {parking_raw.shape}\")\n",
    "print(f\"üóìÔ∏è Date range: {parking_raw['LastUpdatedDate'].min()} to {parking_raw['LastUpdatedDate'].max()}\")\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"\\nüîç First 5 rows of your data:\")\n",
    "parking_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_parking_data(df):\n",
    "    \"\"\"\n",
    "    Process raw parking data into features suitable for ML\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a copy\n",
    "    data = df.copy()\n",
    "    \n",
    "    # Parse datetime information\n",
    "    data['datetime'] = pd.to_datetime(data['LastUpdatedDate'] + ' ' + data['LastUpdatedTime'])\n",
    "    data['hour'] = data['datetime'].dt.hour\n",
    "    data['day_of_week'] = data['datetime'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "    data['is_weekend'] = (data['day_of_week'] >= 5).astype(int)\n",
    "    \n",
    "    # Calculate occupancy rate (current occupancy / total capacity)\n",
    "    data['occupancy_rate'] = data['Occupancy'] / data['Capacity']\n",
    "    \n",
    "    # Map categorical features to numeric\n",
    "    traffic_map = {'low': 1, 'average': 2, 'high': 3}\n",
    "    vehicle_map = {'cycle': 1, 'bike': 2, 'car': 3, 'truck': 4}\n",
    "    \n",
    "    data['traffic_numeric'] = data['TrafficConditionNearby'].map(traffic_map)\n",
    "    data['vehicle_numeric'] = data['VehicleType'].map(vehicle_map)\n",
    "    \n",
    "    # Use queue length and special day flag as-is\n",
    "    data['queue_length'] = data['QueueLength']\n",
    "    data['is_special_day'] = data['IsSpecialDay']\n",
    "    \n",
    "    # Create price target based on occupancy and demand factors\n",
    "    # This is a business rule we'll use as our target for ML\n",
    "    base_price = 10.0  # Base price in currency units\n",
    "    \n",
    "    # Dynamic pricing formula based on parking demand theory\n",
    "    data['target_price'] = base_price * (\n",
    "        1.0 +                                      # Base multiplier\n",
    "        1.5 * data['occupancy_rate'] +             # Occupancy effect (150% max)\n",
    "        0.3 * (data['traffic_numeric'] - 1) / 2 +  # Traffic effect (30% max)\n",
    "        0.2 * data['queue_length'] / 10 +          # Queue effect (20% for queue=10)\n",
    "        0.4 * data['is_special_day'] +             # Special day premium\n",
    "        0.1 * (data['vehicle_numeric'] - 1) / 3    # Vehicle type effect\n",
    "    )\n",
    "    \n",
    "    # Rush hour effects (morning: 7-9, evening: 17-19)\n",
    "    rush_hour_morning = ((data['hour'] >= 7) & (data['hour'] <= 9)).astype(int)\n",
    "    rush_hour_evening = ((data['hour'] >= 17) & (data['hour'] <= 19)).astype(int)\n",
    "    data['is_rush_hour'] = (rush_hour_morning | rush_hour_evening).astype(int)\n",
    "    \n",
    "    # Add rush hour premium\n",
    "    data['target_price'] *= (1 + 0.2 * data['is_rush_hour'])\n",
    "    \n",
    "    # Round price to 2 decimal places\n",
    "    data['target_price'] = np.round(data['target_price'], 2)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Process the data\n",
    "print(\"‚öôÔ∏è Processing and engineering features...\")\n",
    "parking_data = preprocess_parking_data(parking_raw)\n",
    "\n",
    "# Select relevant columns for analysis\n",
    "analysis_columns = [\n",
    "    'datetime', 'hour', 'day_of_week', 'is_weekend', 'is_rush_hour',\n",
    "    'occupancy_rate', 'queue_length', 'traffic_numeric', 'vehicle_numeric',\n",
    "    'is_special_day', 'target_price'\n",
    "]\n",
    "\n",
    "parking_data = parking_data[analysis_columns].copy()\n",
    "\n",
    "print(f\"‚úÖ Processed data shape: {parking_data.shape}\")\n",
    "print(f\"üìä Generated target prices ranging from ${parking_data['target_price'].min():.2f} to ${parking_data['target_price'].max():.2f}\")\n",
    "\n",
    "# Check for any missing values\n",
    "missing_values = parking_data.isnull().sum()\n",
    "if missing_values.sum() > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Missing values detected:\")\n",
    "    print(missing_values[missing_values > 0])\n",
    "    # Drop rows with missing values for this analysis\n",
    "    parking_data = parking_data.dropna()\n",
    "    print(f\"üìä After removing missing values: {parking_data.shape}\")\n",
    "else:\n",
    "    print(\"‚úÖ No missing values found!\")\n",
    "\n",
    "# Display processed data\n",
    "print(\"\\nüîç Processed data sample:\")\n",
    "parking_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"üìà Your Dataset Analysis:\")\n",
    "print(f\"Total samples: {len(parking_data):,}\")\n",
    "print(f\"Features: {len(parking_data.columns)}\")\n",
    "print(f\"Time span: {parking_data['datetime'].min()} to {parking_data['datetime'].max()}\")\n",
    "print(f\"Price range: ${parking_data['target_price'].min():.2f} - ${parking_data['target_price'].max():.2f}\")\n",
    "print(f\"Avg occupancy rate: {parking_data['occupancy_rate'].mean():.1%}\")\n",
    "print(f\"Peak occupancy: {parking_data['occupancy_rate'].max():.1%}\")\n",
    "\n",
    "# Check data distribution\n",
    "print(\"\\nüîç Data Characteristics:\")\n",
    "print(f\"‚Ä¢ Vehicle types: {len(parking_raw['VehicleType'].unique())} types - {list(parking_raw['VehicleType'].unique())}\")\n",
    "print(f\"‚Ä¢ Traffic conditions: {len(parking_raw['TrafficConditionNearby'].unique())} levels - {list(parking_raw['TrafficConditionNearby'].unique())}\")\n",
    "print(f\"‚Ä¢ Special days: {parking_data['is_special_day'].sum()} out of {len(parking_data)} records ({parking_data['is_special_day'].mean():.1%})\")\n",
    "print(f\"‚Ä¢ Rush hour records: {parking_data['is_rush_hour'].sum():,} ({parking_data['is_rush_hour'].mean():.1%})\")\n",
    "\n",
    "# Missing values check\n",
    "missing_count = parking_data.isnull().sum().sum()\n",
    "if missing_count > 0:\n",
    "    print(f\"‚ö†Ô∏è Missing values: {missing_count}\")\n",
    "else:\n",
    "    print(\"‚úÖ No missing values in processed data!\")\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\nüìä Statistical Summary:\")\n",
    "parking_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('üîç Parking Data Exploration', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Price distribution\n",
    "axes[0,0].hist(parking_data['target_price'], bins=30, alpha=0.7, color='skyblue')\n",
    "axes[0,0].set_title('Generated Price Distribution')\n",
    "axes[0,0].set_xlabel('Price ($)')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "\n",
    "# 2. Occupancy vs Price\n",
    "axes[0,1].scatter(parking_data['occupancy_rate'], parking_data['target_price'], \n",
    "                  alpha=0.6, color='coral')\n",
    "axes[0,1].set_title('Occupancy vs Target Price')\n",
    "axes[0,1].set_xlabel('Occupancy Rate')\n",
    "axes[0,1].set_ylabel('Price ($)')\n",
    "\n",
    "# 3. Hourly demand patterns\n",
    "hourly_avg = parking_data.groupby('hour')['occupancy_rate'].mean()\n",
    "axes[0,2].plot(hourly_avg.index, hourly_avg.values, marker='o', color='green')\n",
    "axes[0,2].set_title('Average Occupancy by Hour')\n",
    "axes[0,2].set_xlabel('Hour of Day')\n",
    "axes[0,2].set_ylabel('Avg Occupancy Rate')\n",
    "axes[0,2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Traffic vs Price\n",
    "traffic_prices = parking_data.groupby('traffic_numeric')['target_price'].mean()\n",
    "traffic_labels = ['Low', 'Average', 'High']\n",
    "axes[1,0].bar(range(len(traffic_prices)), traffic_prices.values, color='purple', alpha=0.7)\n",
    "axes[1,0].set_title('Average Price by Traffic Condition')\n",
    "axes[1,0].set_xlabel('Traffic Level')\n",
    "axes[1,0].set_ylabel('Avg Price ($)')\n",
    "axes[1,0].set_xticks(range(len(traffic_prices)))\n",
    "axes[1,0].set_xticklabels(traffic_labels)\n",
    "\n",
    "# 5. Weekend vs Weekday\n",
    "weekend_comparison = parking_data.groupby('is_weekend')[['occupancy_rate', 'target_price']].mean()\n",
    "x = np.arange(2)\n",
    "width = 0.35\n",
    "axes[1,1].bar(x - width/2, weekend_comparison['occupancy_rate'], width, \n",
    "              label='Occupancy Rate', alpha=0.8)\n",
    "axes[1,1].bar(x + width/2, weekend_comparison['target_price']/20, width, \n",
    "              label='Price (scaled)', alpha=0.8)\n",
    "axes[1,1].set_title('Weekend vs Weekday Patterns')\n",
    "axes[1,1].set_ylabel('Value')\n",
    "axes[1,1].set_xticks(x)\n",
    "axes[1,1].set_xticklabels(['Weekday', 'Weekend'])\n",
    "axes[1,1].legend()\n",
    "\n",
    "# 6. Correlation heatmap\n",
    "numeric_cols = ['hour', 'day_of_week', 'occupancy_rate', 'queue_length', \n",
    "                'traffic_numeric', 'vehicle_numeric', 'is_rush_hour', 'target_price']\n",
    "correlation_matrix = parking_data[numeric_cols].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            ax=axes[1,2], cbar_kws={'shrink': 0.8})\n",
    "axes[1,2].set_title('Feature Correlations')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ Key Insights from Your Data:\")\n",
    "print(f\"‚Ä¢ Strongest price correlation: {correlation_matrix['target_price'].abs().sort_values(ascending=False).index[1]} ({correlation_matrix['target_price'].abs().sort_values(ascending=False).iloc[1]:.3f})\")\n",
    "print(f\"‚Ä¢ Peak occupancy hour: {hourly_avg.idxmax()}:00 ({hourly_avg.max():.1%})\")\n",
    "print(f\"‚Ä¢ Highest traffic price: ${traffic_prices.iloc[-1]:.2f} (High traffic)\")\n",
    "print(f\"‚Ä¢ Weekend vs weekday price difference: ${abs(weekend_comparison.loc[1, 'target_price'] - weekend_comparison.loc[0, 'target_price']):.2f}\")
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ü§ñ Experiment 2: Simple ML Baseline (45 minutes)\n",
    "\n",
    "**Goal**: Build and evaluate a basic machine learning model for price prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Prepare Data for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for modeling from your actual data\n",
    "feature_columns = [\n",
    "    'hour', 'day_of_week', 'is_weekend', 'is_rush_hour',\n",
    "    'occupancy_rate', 'queue_length', 'traffic_numeric', \n",
    "    'vehicle_numeric', 'is_special_day'\n",
    "]\n",
    "\n",
    "target_column = 'target_price'  # Our generated price target\n",
    "\n",
    "# Prepare features and target\n",
    "X = parking_data[feature_columns].copy()\n",
    "y = parking_data[target_column].copy()\n",
    "\n",
    "print(f\"üìä Features shape: {X.shape}\")\n",
    "print(f\"üéØ Target shape: {y.shape}\")\n",
    "print(f\"\\nüîß Feature columns from your parking data:\")\n",
    "for i, col in enumerate(feature_columns, 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÇÔ∏è Data Split:\")\n",
    "print(f\"‚Ä¢ Training set: {X_train.shape[0]:,} samples\")\n",
    "print(f\"‚Ä¢ Testing set: {X_test.shape[0]:,} samples\")\n",
    "print(f\"‚Ä¢ Split ratio: {X_test.shape[0]/X.shape[0]:.1%} test\")
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Train Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the model\n",
    "print(\"üîÑ Training Linear Regression model...\")\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "print(\"‚úÖ Model training complete!\")\n",
    "\n",
    "# Calculate performance metrics\n",
    "def calculate_metrics(y_true, y_pred, dataset_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\nüìä {dataset_name} Performance:\")\n",
    "    print(f\"‚Ä¢ MAE (Mean Absolute Error): ${mae:.2f}\")\n",
    "    print(f\"‚Ä¢ RMSE (Root Mean Square Error): ${rmse:.2f}\")\n",
    "    print(f\"‚Ä¢ R¬≤ (Coefficient of Determination): {r2:.3f}\")\n",
    "    \n",
    "    return {'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "# Evaluate on both training and test sets\n",
    "train_metrics = calculate_metrics(y_train, y_train_pred, \"Training Set\")\n",
    "test_metrics = calculate_metrics(y_test, y_test_pred, \"Test Set\")\n",
    "\n",
    "# Check for overfitting\n",
    "overfit_check = train_metrics['R2'] - test_metrics['R2']\n",
    "if overfit_check > 0.1:\n",
    "    print(f\"\\n‚ö†Ô∏è Potential overfitting detected (R¬≤ difference: {overfit_check:.3f})\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Good generalization (R¬≤ difference: {overfit_check:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Analyze Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('ü§ñ Linear Regression Model Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Actual vs Predicted (Test Set)\n",
    "axes[0,0].scatter(y_test, y_test_pred, alpha=0.6, color='blue')\n",
    "axes[0,0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0,0].set_xlabel('Actual Price ($)')\n",
    "axes[0,0].set_ylabel('Predicted Price ($)')\n",
    "axes[0,0].set_title(f'Actual vs Predicted (R¬≤ = {test_metrics[\"R2\"]:.3f})')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Residuals plot\n",
    "residuals = y_test - y_test_pred\n",
    "axes[0,1].scatter(y_test_pred, residuals, alpha=0.6, color='green')\n",
    "axes[0,1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0,1].set_xlabel('Predicted Price ($)')\n",
    "axes[0,1].set_ylabel('Residuals ($)')\n",
    "axes[0,1].set_title('Residuals Plot')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Feature importance (coefficients)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'coefficient': model.coef_\n",
    "}).sort_values('coefficient', key=abs, ascending=True)\n",
    "\n",
    "axes[1,0].barh(range(len(feature_importance)), feature_importance['coefficient'], \n",
    "               color=['red' if x < 0 else 'blue' for x in feature_importance['coefficient']])\n",
    "axes[1,0].set_yticks(range(len(feature_importance)))\n",
    "axes[1,0].set_yticklabels(feature_importance['feature'])\n",
    "axes[1,0].set_xlabel('Coefficient Value')\n",
    "axes[1,0].set_title('Feature Importance (Coefficients)')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Error distribution\n",
    "axes[1,1].hist(residuals, bins=30, alpha=0.7, color='purple')\n",
    "axes[1,1].axvline(x=0, color='r', linestyle='--')\n",
    "axes[1,1].set_xlabel('Prediction Error ($)')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "axes[1,1].set_title(f'Error Distribution (MAE = ${test_metrics[\"MAE\"]:.2f})')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance insights\n",
    "print(\"üéØ Model Insights:\")\n",
    "print(f\"‚Ä¢ Most important feature: {feature_importance.iloc[-1]['feature']} (coeff: {feature_importance.iloc[-1]['coefficient']:.3f})\")\n",
    "print(f\"‚Ä¢ Least important feature: {feature_importance.iloc[0]['feature']} (coeff: {feature_importance.iloc[0]['coefficient']:.3f})\")\n",
    "print(f\"‚Ä¢ Model intercept: ${model.intercept_:.2f}\")\n",
    "print(f\"‚Ä¢ Average prediction error: ${test_metrics['MAE']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Test Model with New Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test scenarios using actual feature columns\n",
    "test_scenarios = pd.DataFrame({\n",
    "    'scenario': ['Rush Hour Peak', 'Weekend Casual', 'High Traffic Event', 'Low Demand', 'Special Day'],\n",
    "    'hour': [8, 14, 19, 11, 10],\n",
    "    'day_of_week': [1, 6, 5, 2, 3],  # Monday, Sunday, Saturday, Wednesday, Thursday\n",
    "    'is_weekend': [0, 1, 1, 0, 0],\n",
    "    'is_rush_hour': [1, 0, 1, 0, 0],  # Rush hour flag\n",
    "    'occupancy_rate': [0.85, 0.45, 0.92, 0.25, 0.70],\n",
    "    'queue_length': [8, 2, 12, 1, 5],\n",
    "    'traffic_numeric': [2, 1, 3, 1, 2],  # 1=low, 2=avg, 3=high\n",
    "    'vehicle_numeric': [3, 2, 4, 2, 3],  # 1=cycle, 2=bike, 3=car, 4=truck\n",
    "    'is_special_day': [0, 0, 0, 0, 1]  # Special event flag\n",
    "})\n",
    "\n",
    "# Make predictions for test scenarios\n",
    "scenario_features = test_scenarios[feature_columns]\n",
    "scenario_predictions = model.predict(scenario_features)\n",
    "\n",
    "# Display results\n",
    "results_df = test_scenarios[['scenario']].copy()\n",
    "results_df['predicted_price'] = np.round(scenario_predictions, 2)\n",
    "results_df['occupancy'] = test_scenarios['occupancy_rate']\n",
    "results_df['traffic'] = test_scenarios['traffic_numeric'].map({1: 'Low', 2: 'Average', 3: 'High'})\n",
    "results_df['vehicle'] = test_scenarios['vehicle_numeric'].map({1: 'Cycle', 2: 'Bike', 3: 'Car', 4: 'Truck'})\n",
    "results_df['special_day'] = test_scenarios['is_special_day'].map({0: 'No', 1: 'Yes'})\n",
    "\n",
    "print(\"üß™ Model Predictions for Parking Scenarios:\")\n",
    "print(\"=\" * 60)\n",
    "for idx, row in results_df.iterrows():\n",
    "    print(f\"üìç {row['scenario']}:\")\n",
    "    print(f\"   üí∞ Predicted Price: ${row['predicted_price']:.2f}\")\n",
    "    print(f\"   üìä Occupancy: {row['occupancy']:.1%}\")\n",
    "    print(f\"   üöó Vehicle Type: {row['vehicle']}\")\n",
    "    print(f\"   üõ£Ô∏è Traffic: {row['traffic']}\")\n",
    "    print(f\"   üéÜ Special Day: {row['special_day']}\")\n",
    "    print()\n",
    "\n",
    "# Business insights from your data\n",
    "print(\"üí° Business Insights from Your Parking Data:\")\n",
    "highest_price_idx = results_df['predicted_price'].idxmax()\n",
    "lowest_price_idx = results_df['predicted_price'].idxmin()\n",
    "\n",
    "print(f\"‚Ä¢ Highest price scenario: {results_df.loc[highest_price_idx, 'scenario']} (${results_df.loc[highest_price_idx, 'predicted_price']:.2f})\")\n",
    "print(f\"‚Ä¢ Lowest price scenario: {results_df.loc[lowest_price_idx, 'scenario']} (${results_df.loc[lowest_price_idx, 'predicted_price']:.2f})\")\n",
    "print(f\"‚Ä¢ Price range: ${results_df['predicted_price'].min():.2f} - ${results_df['predicted_price'].max():.2f}\")\n",
    "print(f\"‚Ä¢ Average predicted price: ${results_df['predicted_price'].mean():.2f}\")\n",
    "print(f\"‚Ä¢ Price variation: {((results_df['predicted_price'].max() - results_df['predicted_price'].min()) / results_df['predicted_price'].mean()):.1%}\")
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ‚öõÔ∏è Experiment 3: Quantum Circuit Simulation (30 minutes)\n",
    "\n",
    "**Goal**: Create and run basic quantum circuits to understand quantum concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Simple Quantum Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple 2-qubit quantum circuit\n",
    "qc = QuantumCircuit(2, 2)\n",
    "\n",
    "# Start with |00‚ü© state (both qubits in 0)\n",
    "print(\"üî¨ Creating 2-qubit quantum circuit...\")\n",
    "\n",
    "# Apply Hadamard gate to first qubit (creates superposition)\n",
    "qc.h(0)  # Now we have (|00‚ü© + |10‚ü©)/‚àö2\n",
    "\n",
    "# Apply CNOT gate (creates entanglement)\n",
    "qc.cx(0, 1)  # Now we have (|00‚ü© + |11‚ü©)/‚àö2 - Bell state!\n",
    "\n",
    "# Add measurements\n",
    "qc.measure([0, 1], [0, 1])\n",
    "\n",
    "# Display the circuit\n",
    "print(\"\\nüìä Quantum Circuit:\")\n",
    "print(qc)\n",
    "\n",
    "# Visualize the circuit (if possible)\n",
    "try:\n",
    "    qc.draw(output='mpl')\n",
    "    plt.title('Simple Quantum Circuit')\n",
    "    plt.show()\n",
    "except:\n",
    "    print(\"üìù Circuit visualization not available in text mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Run Quantum Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up quantum simulator\n",
    "simulator = Aer.get_backend('qasm_simulator')\n",
    "\n",
    "# Execute the circuit\n",
    "print(\"üîÑ Running quantum simulation...\")\n",
    "job = execute(qc, simulator, shots=1000)\n",
    "result = job.result()\n",
    "counts = result.get_counts(qc)\n",
    "\n",
    "print(f\"‚úÖ Simulation complete! (1000 shots)\")\n",
    "print(f\"\\nüìä Measurement Results:\")\n",
    "for state, count in sorted(counts.items()):\n",
    "    probability = count / 1000\n",
    "    print(f\"‚Ä¢ State |{state}‚ü©: {count:3d} times ({probability:.1%})\")\n",
    "\n",
    "# Visualize results\n",
    "try:\n",
    "    plot_histogram(counts)\n",
    "    plt.title('Quantum Measurement Results')\n",
    "    plt.show()\n",
    "except:\n",
    "    # Manual bar plot if qiskit visualization fails\n",
    "    states = list(counts.keys())\n",
    "    frequencies = list(counts.values())\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(states, frequencies, color='skyblue', alpha=0.8)\n",
    "    plt.xlabel('Quantum State')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Quantum Measurement Results (Bell State)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add probability labels\n",
    "    for i, (state, freq) in enumerate(zip(states, frequencies)):\n",
    "        plt.text(i, freq + 10, f'{freq/1000:.1%}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Explain the results\n",
    "print(\"\\nüß† Understanding the Results:\")\n",
    "print(\"‚Ä¢ We created a 'Bell State' - maximum entanglement between qubits\")\n",
    "print(\"‚Ä¢ Expected: 50% |00‚ü© and 50% |11‚ü© (never |01‚ü© or |10‚ü©)\")\n",
    "if '01' in counts or '10' in counts:\n",
    "    error_rate = (counts.get('01', 0) + counts.get('10', 0)) / 1000\n",
    "    print(f\"‚Ä¢ Small error rate: {error_rate:.1%} (due to quantum noise simulation)\")\n",
    "else:\n",
    "    print(\"‚Ä¢ Perfect entanglement observed! üéâ\")\n",
    "    \n",
    "print(\"‚Ä¢ This demonstrates quantum superposition and entanglement!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Quantum Feature Encoding Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple quantum feature encoding for parking data\n",
    "def encode_parking_features(occupancy_rate, queue_length):\n",
    "    \"\"\"\n",
    "    Encode parking features into quantum circuit\n",
    "    \n",
    "    - occupancy_rate: encoded as rotation angle\n",
    "    - queue_length: encoded as conditional gates\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create 2-qubit circuit\n",
    "    qc = QuantumCircuit(2, 2)\n",
    "    \n",
    "    # Encode occupancy as rotation (0.0 ‚Üí 0¬∞, 1.0 ‚Üí œÄ)\n",
    "    occupancy_angle = occupancy_rate * np.pi\n",
    "    qc.ry(occupancy_angle, 0)\n",
    "    \n",
    "    # Encode queue length as conditional operations\n",
    "    if queue_length > 5:  # High queue\n",
    "        qc.x(1)  # Flip second qubit\n",
    "    if queue_length > 10:  # Very high queue\n",
    "        qc.cx(0, 1)  # Add entanglement\n",
    "    \n",
    "    # Measure\n",
    "    qc.measure([0, 1], [0, 1])\n",
    "    \n",
    "    return qc\n",
    "\n",
    "# Test with different parking scenarios\n",
    "scenarios = [\n",
    "    {\"name\": \"Low Demand\", \"occupancy\": 0.2, \"queue\": 1},\n",
    "    {\"name\": \"Medium Demand\", \"occupancy\": 0.6, \"queue\": 5},\n",
    "    {\"name\": \"High Demand\", \"occupancy\": 0.9, \"queue\": 12}\n",
    "]\n",
    "\n",
    "print(\"üß™ Quantum Feature Encoding Experiment:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "for scenario in scenarios:\n",
    "    print(f\"\\nüìç Scenario: {scenario['name']}\")\n",
    "    print(f\"   Occupancy: {scenario['occupancy']:.1%}\")\n",
    "    print(f\"   Queue Length: {scenario['queue']}\")\n",
    "    \n",
    "    # Create quantum circuit for this scenario\n",
    "    qc_scenario = encode_parking_features(scenario['occupancy'], scenario['queue'])\n",
    "    \n",
    "    # Run simulation\n",
    "    job = execute(qc_scenario, simulator, shots=100)\n",
    "    result = job.result()\n",
    "    counts = result.get_counts(qc_scenario)\n",
    "    \n",
    "    # Calculate quantum \"price signal\"\n",
    "    # Higher probability of |11‚ü© ‚Üí higher price\n",
    "    prob_11 = counts.get('11', 0) / 100\n",
    "    quantum_price_signal = prob_11\n",
    "    \n",
    "    print(f\"   Quantum States: {dict(counts)}\")\n",
    "    print(f\"   Quantum Price Signal: {quantum_price_signal:.2f}\")\n",
    "    \n",
    "    results_summary.append({\n",
    "        'scenario': scenario['name'],\n",
    "        'occupancy': scenario['occupancy'],\n",
    "        'queue': scenario['queue'],\n",
    "        'quantum_signal': quantum_price_signal,\n",
    "        'states': dict(counts)\n",
    "    })\n",
    "\n",
    "# Compare quantum signals\n",
    "print(\"\\nüìä Quantum Signal Comparison:\")\n",
    "scenarios_df = pd.DataFrame(results_summary)\n",
    "scenarios_df = scenarios_df.sort_values('quantum_signal')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(scenarios_df['scenario'], scenarios_df['quantum_signal'], \n",
    "               color=['green', 'orange', 'red'], alpha=0.7)\n",
    "plt.ylabel('Quantum Price Signal')\n",
    "plt.title('Quantum Feature Encoding Results')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, scenarios_df['quantum_signal']):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{value:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ Quantum Encoding Insights:\")\n",
    "print(f\"‚Ä¢ Lowest signal: {scenarios_df.iloc[0]['scenario']} ({scenarios_df.iloc[0]['quantum_signal']:.2f})\")\n",
    "print(f\"‚Ä¢ Highest signal: {scenarios_df.iloc[-1]['scenario']} ({scenarios_df.iloc[-1]['quantum_signal']:.2f})\")\n",
    "print(\"‚Ä¢ Quantum circuits can encode multiple features simultaneously!\")\n",
    "print(\"‚Ä¢ Next week: We'll use this for actual quantum machine learning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üìù Week 1 Summary & Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ What We Learned\n",
    "\n",
    "### **Machine Learning Concepts:**\n",
    "1. **Problem Formulation**: Parking pricing as regression problem\n",
    "2. **Feature Engineering**: Time, location, demand, and external factors\n",
    "3. **Model Training**: Linear regression baseline\n",
    "4. **Evaluation Metrics**: MAE, RMSE, R¬≤ for business context\n",
    "5. **Model Interpretation**: Feature importance and business insights\n",
    "\n",
    "### **Quantum Computing Concepts:**\n",
    "1. **Quantum States**: Superposition and entanglement\n",
    "2. **Quantum Gates**: H, X, CNOT for quantum operations\n",
    "3. **Measurement**: Probabilistic outcomes\n",
    "4. **Feature Encoding**: Mapping classical data to quantum states\n",
    "5. **Quantum Advantage**: Parallel processing potential\n",
    "\n",
    "## üîç Key Findings\n",
    "\n",
    "### **From Our Data:**\n",
    "- Occupancy rate is the strongest price predictor\n",
    "- Rush hours and events significantly impact pricing\n",
    "- Location differences create price premiums\n",
    "- Weather and queue length provide additional signals\n",
    "\n",
    "### **From Our Models:**\n",
    "- Linear regression achieved reasonable baseline performance\n",
    "- Model generalizes well (no severe overfitting)\n",
    "- Feature importance aligns with business intuition\n",
    "- Room for improvement with more complex models\n",
    "\n",
    "### **From Quantum Experiments:**\n",
    "- Successfully created and measured quantum states\n",
    "- Demonstrated entanglement with Bell states\n",
    "- Encoded parking features into quantum circuits\n",
    "- Different scenarios produce distinct quantum signatures\n",
    "\n",
    "## üöÄ Next Week Preparation\n",
    "\n",
    "**Questions to Explore:**\n",
    "1. How can quantum circuits improve upon classical ML?\n",
    "2. What quantum algorithms are best for pricing optimization?\n",
    "3. How do we measure quantum advantage quantitatively?\n",
    "\n",
    "**Skills to Develop:**\n",
    "1. Variational quantum circuits (VQC)\n",
    "2. Quantum feature maps\n",
    "3. Hybrid quantum-classical optimization\n",
    "4. Performance benchmarking\n",
    "\n",
    "Ready for Week 2? Let's dive deeper into quantum machine learning! üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
